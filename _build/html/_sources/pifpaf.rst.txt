PifPaf: Composite Fields for Human Pose Estimation
=====================================

| **Authors:** Sven Kreiss, Lorenzo Bertoni, Alexandre Alahi
| **Affiliations:** EPFL VITA lab, CH-1015 Lausanne

The authors propose a new bottom-up method for multi-person 2D human pose estimation, known as PifPaf. This method uses a Part Intensity Field (PIF) to localize body parts and a Part Association Field (PAF) to form human poses. It outperforms previous methods at low resolution and in crowded, cluttered and occluded scenes thanks to (i) the composite filed PAF encoding fine-grained information and (ii) the choice of Laplace loss for regression which incorporates a notion of uncertainty. PifPaf achieves SOTA results on the standard COCO keypoint task and a modified COCO keypoint task for the transportation domain.

The authors propose to extend the notion of fields in pose estimation to go beyond scalar and vector fields to **composite fields**. They introduce a new neural network architecture with two head networks. For each body part or joint, one head network predicts the confidence score, the precision and the size of this joint, which we call a Part Intensity Field (PIF). The other network predicts association between parts, called the Part Association Field (PAF), which is of a new composite structure.

The goal of this method is to estimate human poses in crowded images. The authors address challenges related to low-resolution and partially occluded pedestrians. The figure below presents the PifPaf model.

.. image:: figures/pifpaf-1.png
   :width: 480pt

Part Intensity Fields (PIF)
-------------------------------------

PIF detect and precisely localize body parts. It has composite structure including

- a scalar component for confidence: :math:`c`
- a vector component that points to the closest body part: :math:`(x, y)` with spread :math:`b`
- a scalar component for the size of the joint: :math:`\sigma`

More formally, we have :math:`\mathbf{p}^{ij} = \{p_c^{ij}, p_x^{ij}, p_y^{ij}, p_b^{ij}, p_\sigma^{ij}\}`. The confidence map of a PIF is very coarse. However, we can recover a high resolution confidence map :math:`f(x, y)` using the other components:

.. math::

   f(x, y) = \sum_{ij} p_c^{ij} \mathcal{N}(x, y \mid p_x^{ij}, p_y^{ij}, p_\sigma^{ij})

This equation emphsizes the gird-free nature of the localization. The figure below visualizes the components of the PIF for the left shoulder.

.. image:: figures/pifpaf-2.png
   :width: 480pt

Part Association Fields
-------------------------------------

PAF connects joint locations together into poses. At every location, PAFs predict a confidence, two vectors to the two parts this association is connecting and two widths :math:`b`, represneted by :math:`\mathbf{a}^{ij} = \{a_c^{ij}, a_{x1}^{ij}, a_{y1}^{ij}, a_{b1}^{ij}, a_{x2}^{ij}, a_{y2}^{ij}, a_{b2}^{ij}\}`. Visualizations of the associations between left shoulders and left hips are shown in the figure below.

.. image:: figures/pifpaf-3.png
   :width: 400pt

There are 19 connections for the person class in the COCO dataset. The algorithm to construct the PAF components at a particular feature map location consists of two steps. First, find the closest joint of either of the two types which determines one of the vector components. Second, the ground truth pose determines the other vector component to represent the association. This process is illustrated below.

.. image:: figures/pifpaf-4.png
   :width: 120pt

Adaptive Regression Loss
-------------------------------------

The authors use an L1-type loss to train regressive outputs. They further improve the localization ability of the network by injecting a scale dependence into that regression loss with the SmoothL1 or Laplace Loss.

The SmoothL1 loss allows to tune the radius :math:`r^\text{smooth}` around the origin where it produces softer gradients. For a person instance bounding box area of :math:`A_i` and keypoint size of :math:`\sigma_k`, :math:`r_{i, k}^\text{smooth}` can be set proportioanlly to :math:`\sqrt{A_i}\sigma_k`.

The Laplace loss is another L1-type loss that is attenuated via the predicted spread :math:`b`:

.. math::

   L = \lvert x - \mu \rvert / b + \log (2b)

It is independent of any estimates of :math:`A_i` and :math:`\sigma_k` and is used for all vectorial componenets.

Greedy Decoding
-------------------------------------

A new pose is seeded by PIF vectors with the highest values in the high resolution confidence map :math:`f(x, y)`. Starting from a seed, connections to other joints are added with the help of PAF fields. The algorithm is fast and greedy.

Multiple PAF associations can form connections between the current and the next joint. Given the location of a starting point :math:`\overrightarrow{x}`, the scores :math:`s` of PAF associations :math:`\mathbf{a}` are calculated with

.. math::

   s(\mathbf{a}, \overrightarrow{x}) = a_c \exp \left( - \frac{\lVert \overrightarrow{x} - \overrightarrow{a}_1 \rVert_2}{b_1} \right) f_2(a_{x2}, a_{y2})
